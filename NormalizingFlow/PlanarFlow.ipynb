{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import os\n",
    "import random\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tf.set_random_seed(1234)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Hypter parameters\n",
    "K = 30  # length of the flow\n",
    "learning_rate = 1e-2\n",
    "iterrations = 1e5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sess = tf.InteractiveSession()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# True Density"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size=512\n",
    "DTYPE=tf.float32\n",
    "NP_DTYPE=np.float32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "DATASET = 1\n",
    "if DATASET == 0:\n",
    "    mean = [0.4, 1]\n",
    "    A = np.array([[2, .3], [-1., 4]])\n",
    "    cov = A.T.dot(A)\n",
    "    print(mean)\n",
    "    print(cov)\n",
    "    X = np.random.multivariate_normal(mean, cov, 2000)\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=10, color='red')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X.astype(NP_DTYPE))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(buffer_size=X.shape[0])\n",
    "    dataset = dataset.prefetch(3 * batch_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    data_iterator = dataset.make_one_shot_iterator()\n",
    "    X_train = data_iterator.get_next()\n",
    "elif DATASET == 1:\n",
    "    x2_dist = tfd.Normal(loc=0., scale=4.)\n",
    "    x2_samples = x2_dist.sample(batch_size)\n",
    "    x1 = tfd.Normal(loc=.25 * tf.square(x2_samples),\n",
    "                    scale=tf.ones(batch_size, dtype=DTYPE))\n",
    "    x1_samples = x1.sample()\n",
    "    x_samples = tf.stack([x1_samples, x2_samples], axis=1)\n",
    "    X_train = sess.run(x_samples)\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], s=10)\n",
    "    plt.xlim([-5, 30])\n",
    "    plt.ylim([-10, 10])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_dims = X_train.shape[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Planar Flow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Planar\n",
    "![planar](./images/planar.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class PlanarFlow(tfb.Bijector, tf.Module):\n",
    "    def __init__(self, n_dims, scope=\"planar_flow\", validate_args=False):\n",
    "        super(PlanarFlow, self).__init__(\n",
    "            forward_min_event_ndims=1,\n",
    "            inverse_min_event_ndims=1,\n",
    "            validate_args=validate_args,\n",
    "            name=scope)\n",
    "        with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "            self.u = tf.get_variable('u', [n_dims,], tf.float32)\n",
    "            self.w = tf.get_variable('w', [n_dims,], tf.float32)\n",
    "            self.b = tf.get_variable('b', [1,], tf.float32)\n",
    "        \n",
    "    def h(self, alpha, r=0):\n",
    "        return tf.math.tanh(alpha)\n",
    "\n",
    "    def h_prime(self, alpha, r=0):\n",
    "        return 1.0 - tf.math.tanh(alpha) ** 2.0\n",
    "\n",
    "    def _forward(self, x):\n",
    "        # f(z) = z + u * h(dot(w.T, z) + b)\n",
    "        inter_1 = self.h(tf.tensordot(x, self.w, 1) + self.b)\n",
    "        return tf.add(x, tf.tensordot(inter_1, self.u, 0))\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        self._call_inverse(y, 'inverse')\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        x = self._inverse(y)\n",
    "        psi = tf.tensordot(self.h_prime(tf.tensordot(x, self.w, 1) + self.b), self.w, 0)\n",
    "        det = tf.math.abs(1.0 + tf.tensordot(psi, self.u, 1))\n",
    "        return tf.math.log(det)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_dims = X_train.shape[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construct Planar Flow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# base distribution\n",
    "base_dist = tfd.MultivariateNormalDiag(loc=tf.zeros([2], DTYPE))\n",
    "n_dims = X_train.shape[1]\n",
    "\n",
    "# create a flow\n",
    "bijectors = []\n",
    "for i in range(0, K):\n",
    "    bijectors.append(PlanarFlow(n_dims=n_dims, scope='planar_flow_%d' % i))\n",
    "\n",
    "bijector = tfb.Chain(bijectors=list(reversed(bijectors)), name='chain_of_planar')\n",
    "planar_flow = tfd.TransformedDistribution(\n",
    "    distribution=base_dist,\n",
    "    bijector=bijector\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization (before training)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# visualization\n",
    "x = base_dist.sample(512)\n",
    "samples = [x]\n",
    "names = [base_dist.name]\n",
    "sum_log_det_jacob = 0\n",
    "for bijector in reversed(planar_flow.bijector.bijectors):\n",
    "    x = bijector.forward(x)\n",
    "    samples.append(x)\n",
    "    names.append(bijector.name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = sess.run(samples)\n",
    "f, arr = plt.subplots(1, len(results), figsize=(4 * (len(results)), 4))\n",
    "X0 = results[0]\n",
    "\n",
    "for i in range(len(results)):\n",
    "    X1 = results[i]\n",
    "    idx = np.logical_and(X0[:, 0] < 0, X0[:, 1] < 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='red')\n",
    "    idx = np.logical_and(X0[:, 0] > 0, X0[:, 1] < 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='green')\n",
    "    idx = np.logical_and(X0[:, 0] < 0, X0[:, 1] > 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='blue')\n",
    "    idx = np.logical_and(X0[:, 0] > 0, X0[:, 1] > 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='black')\n",
    "    # arr[i].set_xlim([-2, 2])\n",
    "    # arr[i].set_ylim([-2, 2])\n",
    "    arr[i].set_title(names[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optimize Flow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.function\n",
    "def train_density_estimation(distribution, optimizer, batch):\n",
    "    \"\"\"\n",
    "    Train function for density estimation normalizing flows.\n",
    "    :param distribution: TensorFlow distribution, e.g. tf.TransformedDistribution.\n",
    "    :param optimizer: TensorFlow keras optimizer, e.g. tf.keras.optimizers.Adam(..)\n",
    "    :param batch: Batch of the train data.\n",
    "    :return: loss.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(distribution.trainable_variables)\n",
    "        loss = -tf.reduce_mean(distribution.log_prob(batch))  # negative log likelihood\n",
    "    gradients = tape.gradient(loss, distribution.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, distribution.trainable_variables))\n",
    "\n",
    "    return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss = -tf.reduce_mean(planar_flow.log_prob(X_train))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "NUM_STEPS = int(iterrations)\n",
    "global_step = []\n",
    "np_losses = []\n",
    "for i in range(NUM_STEPS):\n",
    "    _, np_loss = sess.run([train_op, loss])\n",
    "    if i % 1000 == 0:\n",
    "        print(i, np_loss)\n",
    "        global_step.append(i)\n",
    "    \n",
    "    if i % 5000 == 0:\n",
    "        np_losses.append(np_loss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(np_losses)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = sess.run(samples)\n",
    "f, arr = plt.subplots(1, len(results), figsize=(4 * (len(results)), 4))\n",
    "X0 = results[0]\n",
    "for i in range(len(results)):\n",
    "    X1 = results[i]\n",
    "    idx = np.logical_and(X0[:, 0] < 0, X0[:, 1] < 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='red')\n",
    "\n",
    "    idx = np.logical_and(X0[:, 0] > 0, X0[:, 1] < 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='green')\n",
    "\n",
    "    idx = np.logical_and(X0[:, 0] < 0, X0[:, 1] > 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='blue')\n",
    "\n",
    "    idx = np.logical_and(X0[:, 0] > 0, X0[:, 1] > 0)\n",
    "    arr[i].scatter(X1[idx, 0], X1[idx, 1], s=10, color='black')\n",
    "    \n",
    "    # arr[i].set_xlim([-5, 30])\n",
    "    # arr[i].set_ylim([-10, 10])\n",
    "    arr[i].set_title(names[i])\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X1 = sess.run(planar_flow.sample(1000))\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='green', s=2)\n",
    "arr[i].set_xlim([-5, 30])\n",
    "arr[i].set_ylim([-10, 10])\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(np_losses, c='red')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Negative Log-Likelihood')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.14 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}